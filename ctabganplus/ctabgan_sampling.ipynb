{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "sys.path.append('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangtani/.conda/envs/ctabgan_new/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/sangtani/.conda/envs/ctabgan_new/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator BayesianGaussianMixture from version 1.3.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ctabgan_best \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../thesisgan/output/ctabgan_best_model/pklmodel.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/storage.py:181\u001b[0m, in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_from_bytes\u001b[39m(b):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/serialization.py:930\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    928\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    929\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m--> 930\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m deserialized_storage_keys \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mload(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m    934\u001b[0m offset \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;28;01mif\u001b[39;00m f_should_read_directly \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/serialization.py:876\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    872\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_torch_load_uninitialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     deserialized_objects[root_key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m--> 876\u001b[0m         wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    877\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    879\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m deserialized_objects[root_key]\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 176\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/ctabgan_new/lib/python3.10/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "ctabgan_best = pickle.load(open('../thesisgan/output/ctabgan_best_model/pklmodel.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../thesisgan/input/new_train_data.csv')\n",
    "hpo_data = pd.read_csv(\"../thesisgan/input/new_hpo_data.csv\")\n",
    "test_data = pd.read_csv(\"../thesisgan/input/new_test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_syn_data = pd.read_csv(\"../research/best_models/ctabgan_best_model/syn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ML Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.evaluation import get_utility_metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from model.data_preparation import DataPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = DataPrep(train_data, ['proto', 'tcp_ack', 'tcp_psh', 'tcp_rst', 'tcp_syn', 'tcp_fin', 'tos', 'label', 'attack_type'], \n",
    "                     [], {}, [], ['packets', 'src_pt', 'dst_pt', 'duration', 'bytes'], [],\n",
    "                     {\"Classification\": 'attack_type'}, 0.00003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 274245 invalid samples. Have 890755 samples. Want 1164332 samples.\n",
      "Sampled 65101 invalid samples. Have 1100654 samples. Want 1164332 samples.\n",
      "Time taken: 10.380073070526123 seconds\n",
      "Sampled 15454 invalid samples. Have 1151200 samples. Want 1164332 samples.\n",
      "Time taken: 2.449706792831421 seconds\n",
      "Sampled 3748 invalid samples. Have 1163452 samples. Want 1164332 samples.\n",
      "Time taken: 0.6998398303985596 seconds\n",
      "Sampled 881 invalid samples. Have 1166571 samples. Want 1164332 samples.\n",
      "Time taken: 0.22004318237304688 seconds\n"
     ]
    }
   ],
   "source": [
    "more_samples = ctabgan_best.sample(train_data.shape[0])\n",
    "og_more_samples = data_prep.inverse_prep(more_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Results - train data, hpo data, fake data size of hpo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../research/best_models/ctabgan_best_model/table/Classification Results_305_46aa8d602dd61325aed1.table.json') as f:\n",
    "    og_cr = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict = {\"attack_type\": \"le_attack_type\", \"label\": \"le_label\", \"proto\": \"le_proto\", \"tos\": \"le_tos\"}\n",
    "for c in le_dict.keys():\n",
    "    le_dict[c] = LabelEncoder()\n",
    "    test_data[c] = le_dict[c].fit_transform(test_data[c])\n",
    "    train_data[c] = le_dict[c].fit_transform(train_data[c])\n",
    "    hpo_data[c] = le_dict[c].fit_transform(hpo_data[c])\n",
    "    og_syn_data[c] = le_dict[c].fit_transform(og_syn_data[c])\n",
    "    og_more_samples[c] = le_dict[c].fit_transform(og_more_samples[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_cr = pd.DataFrame(data=og_cr[\"data\"], columns=og_cr[\"columns\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Real</th>\n",
       "      <td>78.035474</td>\n",
       "      <td>0.891350</td>\n",
       "      <td>0.584898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake</th>\n",
       "      <td>52.619821</td>\n",
       "      <td>0.832858</td>\n",
       "      <td>0.495669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Difference</th>\n",
       "      <td>25.415653</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.089229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Acc       AUC  F1_Score\n",
       "Type                                     \n",
       "Real        78.035474  0.891350  0.584898\n",
       "Fake        52.619821  0.832858  0.495669\n",
       "Difference  25.415653  0.058492  0.089229"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_cr.drop([\"Model\"],axis=1).groupby([\"Type\"]).mean().sort_values(by=\"F1_Score\", ascending=False).head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original but more - train data, hpo data, fake data size of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  xgb trained on real data\n",
      "Model:  lr trained on real data\n",
      "Model:  dt trained on real data\n",
      "Model:  rf trained on real data\n",
      "Model:  mlp trained on real data\n",
      "Model:  xgb trained on fake data\n",
      "Model:  lr trained on fake data\n",
      "Model:  dt trained on fake data\n"
     ]
    }
   ],
   "source": [
    "more_samples_results, more_samples_cr = get_utility_metrics(train_data, hpo_data, og_more_samples, scaler=\"MinMax\",type={\"Classification\":[\"xgb\",\"lr\",\"dt\",\"rf\",\"mlp\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Look at the data of all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv(\"../thesisgan/output/ctabgan_best_model/table/ctabgan_best_reports.csv\")\n",
    "results = pd.read_csv(\"../thesisgan/output/ctabgan_best_model/table/ctabgan_best_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Original with hpo sized samples (train-hpo (hposized))',\n",
       "       'Original with train sized samples (train-hpo (trainsized))',\n",
       "       'Original with hpo sized samples, more test data (train- test+hpo))',\n",
       "       'Original with train sized samples, more test data (train- test+hpo))'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"Desc\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Type</th>\n",
       "      <th>Desc</th>\n",
       "      <th>SE_Acc</th>\n",
       "      <th>SE_AUC</th>\n",
       "      <th>SE_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.035474</td>\n",
       "      <td>0.891350</td>\n",
       "      <td>0.584898</td>\n",
       "      <td>Real</td>\n",
       "      <td>Original with hpo sized samples (train-hpo (hp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.619821</td>\n",
       "      <td>0.832858</td>\n",
       "      <td>0.495669</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Original with hpo sized samples (train-hpo (hp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.415653</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.089229</td>\n",
       "      <td>Difference</td>\n",
       "      <td>Original with hpo sized samples (train-hpo (hp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.549789</td>\n",
       "      <td>0.887136</td>\n",
       "      <td>0.574203</td>\n",
       "      <td>Real</td>\n",
       "      <td>Original with train sized samples (train-hpo (...</td>\n",
       "      <td>0.072118</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.832470</td>\n",
       "      <td>0.849401</td>\n",
       "      <td>0.453714</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Original with train sized samples (train-hpo (...</td>\n",
       "      <td>0.087015</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.717319</td>\n",
       "      <td>0.037735</td>\n",
       "      <td>0.120488</td>\n",
       "      <td>Difference</td>\n",
       "      <td>Original with train sized samples (train-hpo (...</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>81.974390</td>\n",
       "      <td>0.929670</td>\n",
       "      <td>0.650088</td>\n",
       "      <td>Real</td>\n",
       "      <td>Original with hpo sized samples, more test dat...</td>\n",
       "      <td>0.046067</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53.162439</td>\n",
       "      <td>0.834595</td>\n",
       "      <td>0.503570</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Original with hpo sized samples, more test dat...</td>\n",
       "      <td>0.061163</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.811952</td>\n",
       "      <td>0.095075</td>\n",
       "      <td>0.146519</td>\n",
       "      <td>Difference</td>\n",
       "      <td>Original with hpo sized samples, more test dat...</td>\n",
       "      <td>-0.015096</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81.974390</td>\n",
       "      <td>0.929670</td>\n",
       "      <td>0.650088</td>\n",
       "      <td>Real</td>\n",
       "      <td>Original with train sized samples, more test d...</td>\n",
       "      <td>0.046067</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54.271889</td>\n",
       "      <td>0.860339</td>\n",
       "      <td>0.484045</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Original with train sized samples, more test d...</td>\n",
       "      <td>0.061173</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.702501</td>\n",
       "      <td>0.069331</td>\n",
       "      <td>0.166044</td>\n",
       "      <td>Difference</td>\n",
       "      <td>Original with train sized samples, more test d...</td>\n",
       "      <td>-0.015107</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>-0.000032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Acc       AUC  F1_Score        Type  \\\n",
       "0   78.035474  0.891350  0.584898        Real   \n",
       "1   52.619821  0.832858  0.495669        Fake   \n",
       "2   25.415653  0.058492  0.089229  Difference   \n",
       "3   76.549789  0.887136  0.574203        Real   \n",
       "4   52.832470  0.849401  0.453714        Fake   \n",
       "5   23.717319  0.037735  0.120488  Difference   \n",
       "6   81.974390  0.929670  0.650088        Real   \n",
       "7   53.162439  0.834595  0.503570        Fake   \n",
       "8   28.811952  0.095075  0.146519  Difference   \n",
       "9   81.974390  0.929670  0.650088        Real   \n",
       "10  54.271889  0.860339  0.484045        Fake   \n",
       "11  27.702501  0.069331  0.166044  Difference   \n",
       "\n",
       "                                                 Desc    SE_Acc    SE_AUC  \\\n",
       "0   Original with hpo sized samples (train-hpo (hp...       NaN       NaN   \n",
       "1   Original with hpo sized samples (train-hpo (hp...       NaN       NaN   \n",
       "2   Original with hpo sized samples (train-hpo (hp...       NaN       NaN   \n",
       "3   Original with train sized samples (train-hpo (...  0.072118  0.000527   \n",
       "4   Original with train sized samples (train-hpo (...  0.087015  0.000612   \n",
       "5   Original with train sized samples (train-hpo (... -0.014897 -0.000085   \n",
       "6   Original with hpo sized samples, more test dat...  0.046067  0.000303   \n",
       "7   Original with hpo sized samples, more test dat...  0.061163  0.000436   \n",
       "8   Original with hpo sized samples, more test dat... -0.015096 -0.000133   \n",
       "9   Original with train sized samples, more test d...  0.046067  0.000303   \n",
       "10  Original with train sized samples, more test d...  0.061173  0.000418   \n",
       "11  Original with train sized samples, more test d... -0.015107 -0.000115   \n",
       "\n",
       "       SE_F1  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3   0.000826  \n",
       "4   0.000831  \n",
       "5  -0.000005  \n",
       "6   0.000552  \n",
       "7   0.000573  \n",
       "8  -0.000020  \n",
       "9   0.000552  \n",
       "10  0.000585  \n",
       "11 -0.000032  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
